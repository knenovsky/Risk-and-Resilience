---
title: "06_figures_charts"
author: "Kolja Nenoff"
date: "2023-07-08"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls())
library(rstudioapi)
library(magrittr)
library(tidyverse)
library(data.table)
library(parallel)
library(dimRed)
library(devtools)
library(igraph)
library(energy)
library(ggrepel)
library(ggalt)
library(ggraph)
library(trend)
library(riverplot)
library(RANN)
library(RJSONIO)
library(RSpectra)
library(pcaMethods)
require(broom)
require(GGally)
require(ggpubr)
require(xgboost)
require(caret)
require(pdp)
require(iml)
require(data.table)
require(tidyverse)
require(cowplot)
require(readxl)
```

```{r}
wdi_explained<-fread("../data/WDI_data_230609/WDI_CSV/WDISeries.csv")
dimred2021_knn250_2<-fread("../output/02_230612_Dimred_ExcessMort_annual.csv") 



## Download the covid data from Our world in data if this file is not available in your data folder and run a script to make it monthly
load("../data/07_230504_OWID_dataset")

col_pal <- c("#1F968B",  "#7570b3", "#e7298a", "#3CBB75","yellow3", "orange","slategrey")
```

# data
```{r,Excess Mortility WHO Set}
getwd()
excessCounrty_year<-read_excel("../data/230224_nature_WHO_excess_death/2022-03-25_covid-19_gem/WHO_COVID_Excess_Deaths_EstimatesByCountry.xlsx",sheet = 2)
excessCounrty_month<-read_excel("../data/230224_nature_WHO_excess_death/2022-03-25_covid-19_gem/WHO_COVID_Excess_Deaths_EstimatesByCountry.xlsx",sheet = 2)
excessCounrty_covariates<-read_excel("../data/230224_nature_WHO_excess_death/2022-03-25_covid-19_gem/WHO_COVID_Excess_Deaths_EstimatesByCountry.xlsx",sheet = 3)
excessRegion_year<-read_excel("../data/230224_nature_WHO_excess_death/2022-03-25_covid-19_gem/WHO_COVID_Excess_Deaths_EstimatesByRegion.xlsx",sheet = 2)
excessRegion_income<-read_excel("../data/230224_nature_WHO_excess_death/2022-03-25_covid-19_gem/WHO_COVID_Excess_Deaths_EstimatesByIncome.xlsx",sheet = 2)
excessRegion_income %>% group_by(income) %>% 

  summarise(p_value_mort=sum(excess.mean)/sum(expected.mean)*100,excess_comul=sum(excess.mean))
excessCounrty_year_pvalue<-excessCounrty_year %>% group_by(country,iso3,year) %>% 
  summarise(p_value_mort=sum(excess.mean)/sum(expected.mean)*100,excess_comul=sum(excess.mean))
excessCounrty_year %>% filter(year==2020)-> excessCounrty_year_2020
p_value_global_2020=sum(excessCounrty_year_2020$excess.mean,na.rm = T)/sum(excessCounrty_year_2020$expected.mean,na.rm = T)*100
excessCounrty_year %>% filter(year==2021)-> excessCounrty_year_2020
p_value_global_2021=sum(excessCounrty_year_2020$excess.mean,na.rm = T)/sum(excessCounrty_year_2020$expected.mean,na.rm = T)*100
excessCounrty_monthly_pvalue<-excessCounrty_year  %>% 
  mutate(p_value_mort=(excess.mean)/(expected.mean)*100)

excessCounrty_monthly_pvalue2<-excessCounrty_monthly_pvalue %>% arrange(country,year,month) %>% rename(`Country Code`=iso3) %>% 
  mutate(date = as.Date(paste(year, month, "01", sep = "-"), format = "%Y-%m-%d"),identifier=paste0(`Country Code`,"_",year(date),"_",month(date)),identifier_CountryYear=paste0(`Country Code`,"_",year(date)))%>% filter(date>"2020-02-01")
```
## Temperature
```{r}
tempyear<-read.csv("../data/230808_Cocap_01_countries_mean_temp.csv")
tempyear$X<-NULL
tempyear %>%  filter(year%in%c(2020,2021))->tempyear2

tempyear2 %>% pivot_longer(names_to = "month",
               "Jan":"Dec",
               values_drop_na = TRUE) %>% mutate(month=case_when(month%in%"Jan"~1,
                                                                 month%in%"Feb"~2,
                                                                 month%in%"Mar"~3,
                                                                 month%in%"Apr"~4,
                                                                 month%in%"May"~5,
                                                                 month%in%"Jun"~6,
                                                                 month%in%"Jul"~7,
                                                                 month%in%"Aug"~8,
                                                                 month%in%"Sep"~9,
                                                                 month%in%"Oct"~10,
                                                                 month%in%"Nov"~11,
                                                                 month%in%"Dec"~12))-> tempyear3
tempyear3

```


# functions
```{r}
load("00_toolbox.R")
```



```{r}
thisData<-dimred2021_knn250_2[] %>% filter(year%in% 2019)
IsoYear<-"2019"
Label<-"pscore_mean"
candidates<-c("iso1","iso2","iso3","iso4","iso5","iso6","iso7")
dimredCountries<-thisData$`Country Code` %>%  unique
ExmortCountries<-excessCounrty_monthly_pvalue$iso3 %>%  unique 
thisisOWID %>% group_by(location) %>% summarise(numberofmonth=monthyear %>% length())
owidCountries<-thisisOWID$iso_code %>%  unique
inter_countries<-intersect(dimredCountries,ExmortCountries)
our_countries<-intersect(owidCountries,inter_countries)

```
# Excess Death waves

```{r}

excessmonthy <- excessCounrty_monthly_pvalue %>% arrange(country,year,month) %>% rename(`Country Code`=iso3) %>% 
  mutate(date = as.Date(paste(year, month, "01", sep = "-"), format = "%Y-%m-%d"),identifier=paste0(`Country Code`,"_",year(date),"_",month(date)))%>% filter(date>"2020-02-01") %>% merge( . , thisisOWID,by.x="identifier",by.y="monthyear")



```



## wavefinder



```{r}
excessmonthy %>%  arrange(date)%>% filter(new_cases_per_million>1) %>% select(`Country Code` ,date,p_value_mort,new_cases_per_million)
# Assuming you have your dataset 'thiscountry' with the 'p_value_mort' column
FirstWave<-data.frame(Countries=our_countries,"Endfirstwave"="")

for(i in our_countries){

data_Country<-excessmonthy %>%  filter(`Country Code` %in% i) %>%  arrange(date)%>% select(`Country Code` ,date,p_value_mort,new_cases_per_million)
data_Country$p_value_mort_smoothed <- rollmean(data_Country$p_value_mort, k = 3, fill = NA, align = "center")

results <- calculate_waves(data_Country)
waves <- results$waves
first_global_minima <- results$first_global_minima
if(i=="CHN"){
  FirstWave[FirstWave$Countries%in%i,"Endfirstwave"]<-"2021-02-01"
}
else if(i=="SYC"){
  FirstWave[FirstWave$Countries%in%i,"Endfirstwave"]<-"2020-10-01"
}


else{
FirstWave[FirstWave$Countries%in%i,"Endfirstwave"]<-as.character(first_global_minima)
}
}

FirstWave2<-FirstWave %>% drop_na()



```


## Split the data into first wave and after first wave
```{r}


ExcessMort_Moratality<-data.frame()

for (i in 1:nrow(FirstWave2)){
  thisdata<-candidates %>%  filter(`Country Code`%in%  FirstWave2[i,"Countries"]) 
  if(nrow(thisdata)==22)
    {
    firstwave<-thisdata %>% filter(date<=FirstWave2[i,"Endfirstwave"]) %>% group_by(`Country Code`) %>% 
  summarise(p_value_mort_Firstwave=sum(excess.mean)/sum(expected.mean)*100,excess_comul=sum(excess.mean))
    Afterwave<-thisdata %>% filter(date>FirstWave2[i,"Endfirstwave"]) %>% group_by(`Country Code`) %>% 
  summarise(p_value_mort_Firstwave=sum(excess.mean)/sum(expected.mean)*100,excess_comul=sum(excess.mean))
    adder<-data.frame("Country"=FirstWave2[i,"Countries"],"Exmort_FirstWave"=firstwave$p_value_mort_Firstwave,"Exmort_AfterWave"=Afterwave$p_value_mort_Firstwave)
   ExcessMort_Moratality<-rbind(ExcessMort_Moratality,adder)
    }
  
  
}


```


### First wave

```{r}
thisData<-dimred2021_knn250_2[]%>% filter(year%in%2019) %>% select(features,"Country Code") 
thisdata2<-merge(thisData,candidates,by.x="Country Code",by.y="Country Code")


IsoYear<-"2019"
Label<-"Exmort_AfterWave"
candidates<-c("iso1","iso2","iso3","iso4","iso5","iso6","iso7")


custom_control <- trainControl(
  method = "cv",
  number = 30,  # Increase the number of folds
  search = "random",
  allowParallel = TRUE
  
)

param_grid <- expand.grid(
  nrounds = c(50,100),
  eta = c(0.05),
  max_depth = c(2, 4),
  colsample_bytree = c( 1),
  subsample = c(1),
  gamma = c(0),
  min_child_weight = c(0)
)

# Set the proportion for the test set (e.g., 0.2 for 20% test data)

```


```{r}
test_proportion <- 0.6
thisdata3<-thisdata2[thisdata2$year%in% 2019,] %>%  select(candidates,Label) %>% drop_na()
index <- caret::createDataPartition(thisdata3$iso1, p = test_proportion, list = FALSE)
# Split the data into training and test sets
train_data <- thisdata3[index, ]
test_data <- thisdata3[-index, ]


# Train the XGBoost model using the function
final_model <- train_xgboost_model(train_data, Label, candidates, custom_control, param_grid)
# Assuming you have the 'finalmodel' and 'test_data' from the previous steps
predictedValue<-postResample(
      predict(final_model, 
          test_df %>% dplyr::select(-label)),  
        test_df %>% pull(label)
      )
predictedValue


```


### Agnostic
```{r}
shap_values <- shap.values(xgb_model = final_model$finalModel, X_train = as.matrix(train_df %>% dplyr::select(all_of(features))))
xgboost::xgb.ggplot.shap.summary(data = as.matrix(train_data %>% 
  dplyr::select( -Label)),
  model = final_model$finalModel) +scale_color_viridis("Feature Value")+ theme_bw() + xlab("Features")+ylab("Shapley value")+theme(legend.position = "left")


pdp_all <- lapply(candidates, function(x){#
    pdp <- pdp::partial(final_model, pred.var = c(x), chull = TRUE)
    df <- pdp %>%
    gather(-yhat, key = key, value = value)
  })
pdp_all2<-do.call(rbind,pdp_all)
pdp_all2 %>%   mutate(key = factor(key, levels=candidates)) %>%  ggplot(pdp_all2,
       mapping = aes_string(x = "value",
                           y = "yhat"))+
  geom_point()+
  geom_smooth(method = "loess", se=T)+
  theme_minimal()+
  facet_wrap(~(key), scales = "free", ncol = 3) 
```


# what about a model that indicates if there is wave present and we take 2019 for 2020 and 2020 for 2021

# Final Monthly analysis

```{r}
features<-c("iso1","iso2","iso3","iso4","iso5","iso6","iso7")
# Everytime we are looking at iso of the year before for matching them we are taking the year after that
dimred2019<-dimred2021_knn250_2[]%>% filter(year%in%2019) %>%  
    mutate(identifier_CountryYear=paste0(`Country Code`,"_","2020")) %>%    
    select(features,"identifier_CountryYear") 
dimred2020<-dimred2021_knn250_2[]%>% filter(year%in%2020) %>% 
    mutate(identifier_CountryYear=paste0(`Country Code`,"_","2021")) %>%   
    select(features,"identifier_CountryYear") 

Dimred_input<-rbind(dimred2019,dimred2020)

Xgboostinput_first<-merge(Dimred_input,excessCounrty_monthly_pvalue2,by="identifier_CountryYear")
Xgboostinput_second<-merge(Xgboostinput_first,thisisOWID,by.y="monthyear",by.x = "identifier")

Xgboostinput<-tempyear3  %>% mutate(isoyearmonth=paste0(ISO_code,"_",year,"_",month)) %>% rename(meanTemp=value) %>%  select(isoyearmonth,meanTemp)%>% merge(Xgboostinput_second, . , by.x = "identifier",by.y = "isoyearmonth")
#Xgboostinput%>% fwrite("../results/06_Dimred_Exmort_monthly.csv")
```


```{r}
Xgboostinput<- fread("../results/06_Dimred_Exmort_monthly.csv")
Label<-"p_value_mort"
features<-c("iso1","iso2","iso3","iso4","iso5","iso6","iso7","new_cases_smoothed_per_million","meanTemp")


custom_control <- trainControl(
  method = "cv",
  number = 30,  # Increase the number of folds
  search = "random",
  allowParallel = TRUE
  
)

param_grid <- expand.grid(
  nrounds = c(50,100),
  eta = c(0.05),
  max_depth = c(2, 4),
  colsample_bytree = c( 1),
  subsample = c(1),
  gamma = c(0),
  min_child_weight = c(0)
)

# Set the proportion for the test set (e.g., 0.2 for 20% test data)

test_proportion <- 0.8
Xgboostinput_filtered<-Xgboostinput %>%  select(features,Label) %>% drop_na()
index <- caret::createDataPartition(Xgboostinput_filtered$iso1, p = test_proportion, list = FALSE)
# Split the data into training and test sets
train_data <- Xgboostinput_filtered[index, ]
test_data <- Xgboostinput_filtered[-index, ]


# Train the XGBoost model using the function
trainedModel<- train_xgboost_model(train_data, Label, features, custom_control, param_grid)
# Assuming you have the 'finalmodel' and 'test_data' from the previous steps
predictedValue<-postResample(
      predict(trainedModel, 
          test_data %>% dplyr::select(features)),  
        test_data %>% pull(Label)
      )
predictedValue

```


## Agnostic
```{r}
shap_values <- shap.values(xgb_model = trainedModel$finalModel, X_train = as.matrix(train_data %>% dplyr::select(all_of(features))))
xgboost::xgb.ggplot.shap.summary(data = as.matrix(train_data %>% 
  dplyr::select(features)),
  model = trainedModel$finalModel) +scale_color_viridis("Feature Value")+ theme_bw() + xlab("Features")+ylab("Shapley value")+theme(legend.position = "left")


pdp_all <- lapply(features, function(x){#
    pdp <- pdp::partial(trainedModel, pred.var = c(x), chull = TRUE)
    df <- pdp %>%
    gather(-yhat, key = key, value = value)
  })
pdp_all2<-do.call(rbind,pdp_all)
pdp_all2 %>%   mutate(key = factor(key, levels=features)) %>%  ggplot(pdp_all2,
       mapping = aes_string(x = "value",
                           y = "yhat"))+
  geom_point()+
  geom_smooth(method = "loess", se=T)+
  theme_minimal()+
  facet_wrap(~(key), scales = "free", ncol = 3) 

```

