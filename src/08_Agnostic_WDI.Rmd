---
title: "08_Agnostic_WDI"
author: "Kolja Nenoff"
date: "2023-08-14"
output: html_document
---
```{r setup, include=FALSE}
rm(list = ls())
library(rstudioapi)
library(magrittr)
library(tidyverse)
library(data.table)
library(parallel)
library(dimRed)
library(devtools)
library(igraph)
library(energy)
library(ggrepel)
library(ggalt)
library(ggraph)
library(trend)
library(riverplot)
library(RANN)
library(RJSONIO)
library(RSpectra)
library(pcaMethods)
require(broom)
require(GGally)
require(ggpubr)
require(xgboost)
require(caret)
require(pdp)
require(iml)
require(data.table)
require(tidyverse)
require(cowplot)
require(readxl)
```
```{r}
wdi_explained<-fread("../data/WDI_data_230609/WDI_CSV/WDISeries.csv")
#load("../data/07_230504_OWID_dataset")
wdi_data<-fread("../data/05_WDI_data.csv")
dimred2021_knn250_2<-fread("../output/02_230612_Dimred_ExcessMort_annual.csv")
col_pal <- c("#1F968B",  "#7570b3", "#e7298a", "#3CBB75","yellow3", "orange","slategrey")
```

#  Tracing back the DImred XGboost for WDI and Dimred
```{r}


dimred2021_knn250_2$pscore_level<-as.factor(ntile(dimred2021_knn250_2$pscore_mean, 4))
dimred2021_knn250_2 %>% group_by(pscore_level) %>% summarize(Min=min(pscore_mean),Max=max(pscore_mean)) %>% mutate(p_score_level_label=paste0(Min," to ",Max)) %>% 
  left_join(dimred2021_knn250_2, . ,by="pscore_level")-> dimred2021_knn250_3
dimred2021_knn250_3 %>% 
  # mutate(pscore_cat2 = fct_relevel(pscore_cat, 
  #           "", "<0", "0 to <5","5 to <10","10 to <20","20 to <30","30 to <40","40 to <50", ">=50" )) %>% 
  mutate(p_score_level_label = fct_relevel(p_score_level_label,
            "-6.4 to 5.5" , "5.5 to 8.6" , "8.6 to 18.1" ,"18.1 to 97.1"  )) %>%
  mutate(p_score_level_label2=case_when(p_score_level_label%in% "18.1 to 97.1" & RegionSoviet %in% "Post-Soviet"~"High Soviets",
                                            p_score_level_label%in% "18.1 to 97.1" & RegionSoviet %in% "Latin America & Caribbean"~"High Latin",
                                               p_score_level_label%in% "18.1 to 97.1" ~"High other",
                                              TRUE~p_score_level_label ))    %>%                                                                                     
  # mutate(p_score_level_label = fct_relevel(p_score_level_label, 
  #           "-6.4 to 4.4","4.4 to 7" ,  "7 to 11.6" ,"11.6 to 20.1" ,"20.1 to 97.1" )) %>% 

  filter(!is.na(pscore_level))->dimred2021_knn250_3 


add_col<-c(colnames(wdi_data)[!(colnames(wdi_data)%in% colnames(dimred2021_knn250_3))])



wdi_data %>% mutate(identifier=paste0(`Country Code`,year)) %>%select(any_of(c("Country Code","year","identifier",add_col)))-> wdi_data2
dimred2021_knn250_3 %>% mutate(identifier=paste0(`Country Code`,year)) -> dimred2021_knn250_4

left_join(dimred2021_knn250_4,wdi_data2 %>% select(any_of(c("identifier",add_col))),"identifier") %>%  filter() -> dimred2021_knn250_5


fortheseIndicators<-colnames(dimred2021_knn250_5)[colnames(dimred2021_knn250_5)%in% wdi_explained$`Series Code`]
Xgboostinput2<-dimred2021_knn250_5
```


```{r}
custom_control <- trainControl(
  method = "cv",
  number = 30,  # Increase the number of folds
  search = "random",
  allowParallel = TRUE
  
)

param_grid <- expand.grid(
  nrounds = c(50,100),
  eta = c(0.05),
  max_depth = c(2, 4),
  colsample_bytree = c( 1),
  subsample = c(1),
  gamma = c(0),
  min_child_weight = c(0)
)


```



```{r}

```

```{r}
filesPC<-list.files("../output/wdi_dim_corr/summarystat_pc/")
filesPC_already<-str_remove_all(filesPC,"PC_corr") %>% str_remove_all( . ,"_summary.csv")
indicator<-fortheseIndicators[!(fortheseIndicators%in% filesPC_already)]
process_indicator(indicator[1])
indicator<-indicator[!(indicator %in% "TX.VAL.TECH.CD")]
num_cores <- 1
system.time({
  clust <- makeCluster(num_cores)
  parallel::clusterExport(clust, "Xgboostinput2", envir = environment())
  parallel::clusterExport(clust, "train_xgboost_model", envir = environment())
  parallel::clusterExport(clust, "custom_control", envir = environment())
  parallel::clusterExport(clust, "param_grid", envir = environment())
  parallel::clusterExport(clust, "get_wdi_trajectory", envir = environment())
  parallel::clusterExport(clust, "dimred2021_knn250_5", envir = environment())
  parallel::clusterExport(clust, "wdi_explained", envir = environment())
  parallel::clusterExport(clust, "fortheseIndicators", envir = environment())
  a <- parLapply(clust, indicator[3], process_indicator)})

 #%>%  select(TX.VAL.TECH.CD) %>%  drop_na()
stopCluster(cl)
# Access the results for each indicator

```


```{r}
# {
# PC_Corrtable %>%  drop_na()%>% fwrite(paste0("../output/wdi_dim_corr/summarystat_pc/PC_corr",Label,"_summary.csv"),)
# pdp_all2 %>% fwrite(paste0("../output/wdi_dim_corr/summarystat/",Label,"_summary.csv"),)
# shapleyplot %>% ggsave(file=paste0("../output/wdi_dim_corr/plots/",Label,"_shapley_plot.png"),device="png")
# indicatorplot %>% ggsave(file=paste0("../output/wdi_dim_corr/plots/",Label,"_indicator_plot.png"),device="png")
# }
```


### Agnostic
```{r}

#shap_values <- shap.values(xgb_model = trainedModel$finalModel, X_train = as.matrix(train_data %>% dplyr::select(all_of(features))))


pdp_all <- lapply(features, function(x){#
    pdp <- pdp::partial(trainedModel, pred.var = c(x), chull = TRUE)
    df <- pdp %>%
    gather(-yhat, key = key, value = value)
  })
pdp_all2<-do.call(rbind,pdp_all)
pdp_all2 %>%   mutate(key = factor(key, levels=features)) %>%  ggplot(pdp_all2,
       mapping = aes_string(x = "value",
                           y = "yhat"))+
  geom_point()+
  geom_smooth(method = "loess", se=T)+
  theme_minimal()+
  facet_wrap(~(key), scales = "free", ncol = 3)  + ggtitle("Second Wave")

```


# WDI prediction Shapley values

```{r}
listi<-list.files("../output/wdi_dim_corr/summarystat_pc/")

entireListi<-data.frame()
for(i in 1:length(listi)){
  a<-fread(paste0("../output/wdi_dim_corr/summarystat_pc/",listi[i]))
  
  entireListi<- rbind(entireListi,a)
}
options(scipen = 999)
entireListi %>%  unique-> asd
merge(wdi_explained[,c(1:3)],asd,by.x="Series Code",by.y="indiacator")->asda

asda %>%  filter(key%in% "iso3",value< -0.1)%>% arrange(desc(yhat),desc(Rsquared)) %>% group_by(key,`Series Code`,`Indicator Name`,Rsquared) %>% summarize(Shapmean=mean(yhat))%>%  unique-> indicator
```

```{r}
energycorr<-fread("../results/corrTable/05_CorrTable_iso2_quantiles_shapleys_2019to2021_all.csv")
iso2Imp
```



# shapley PC

```{r}
Xgboostinput<- fread("../results/06_Dimred_Exmort__withpc_monthly.csv")
Xgboostinput<-Xgboostinput %>% mutate(yearmon=as.numeric(as.factor(str_remove(pattern = "[a-zA-Z_]+",identifier)))) 

Label<-"p_value_mort"
features<-c("PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10","PC11","PC12","PC13","PC14")

#features<-c("iso1","iso2","iso3","iso4","iso5","iso6","iso7","new_cases_smoothed_per_million","PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10","PC11","PC12","PC13","PC14")

set.seed(123)
custom_control <- trainControl(
  method = "cv",
  number = 30,  # Increase the number of folds
  search = "random",
  allowParallel = TRUE
  
)

param_grid <- expand.grid(
  nrounds = c(50,100),
  eta = c(0.05),
  max_depth = c(2, 4),
  colsample_bytree = c( 1),
  subsample = c(1),
  gamma = c(0),
  min_child_weight = c(0)
)

# Set the proportion for the test set (e.g., 0.2 for 20% test data)

test_proportion <- 0.8
Xgboostinput_filtered<-Xgboostinput %>%  select(features,Label) %>% drop_na()
index <- caret::createDataPartition(Xgboostinput_filtered$p_value_mort, p = test_proportion, list = FALSE)
# Split the data into training and test sets
train_data <- Xgboostinput_filtered[index, ]
test_data <- Xgboostinput_filtered[-index, ]


# Train the XGBoost model using the function
trainedModel<- train_xgboost_model(train_data, Label, features, custom_control, param_grid)

# Assuming you have the 'finalmodel' and 'test_data' from the previous steps
predictedValue<-postResample(
      predict(trainedModel, 
          test_data %>% dplyr::select(features)),  
        test_data %>% pull(Label)
      )
predictedValue


```
26 % pc 1-5 ,33 %  Iso 1 -5 and 31.2 pc 1-14, and iso 3- 7 32

AAAALSO es sieht so aus als 

## Agnostic
```{r}
#shap_values <- shap.values(xgb_model = trainedModel$finalModel, X_train = as.matrix(train_data %>% dplyr::select(all_of(features))))
xgboost::xgb.ggplot.shap.summary(data = as.matrix(train_data %>% 
  dplyr::select(features)),
  model = trainedModel$finalModel) +scale_color_viridis("Feature Value")+ theme_bw() + xlab("Features")+ylab("Shapley value")+theme(legend.position = "left")


pdp_all <- lapply(features, function(x){#
    pdp <- pdp::partial(trainedModel, pred.var = c(x), chull = TRUE)
    df <- pdp %>%
    gather(-yhat, key = key, value = value)
  })
pdp_all2<-do.call(rbind,pdp_all)
pdp_all2 %>%   mutate(key = factor(key, levels=c("PC1","PC2","PC3","PC4","PC5","PC10"))) %>%  ggplot(pdp_all2,
       mapping = aes_string(x = "value",
                           y = "yhat"))+
  geom_point()+
  geom_smooth(method = "loess", se=T)+
  theme_minimal()+
  facet_wrap(~(key), scales = "free", ncol = 3) 

```
```{r}
library("SHAPforxgboost"); library("ggplot2"); library("xgboost")
shap_long <- shap.prep(xgb_model = trainedModel$finalModel, X_train  = as.matrix(train_data %>% dplyr::select(all_of(features))))
# is the same as: using given shap_contrib
shap.plot.summary(shap_long)
```


